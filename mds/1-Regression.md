# Regression

`回归分析`是研究输入输出的关系，输出的是**标量(scalar)**，需要找到一个合适的函数使其能够预测出尽可能准确的标量值（函数值）。例如自动驾驶中各种传感器传入的数据就是input，输出的标量值则是方向盘旋转角度。



本节以`预测宝可梦进化后的CP值`(战斗能力)为例，宝可梦本身用$x$表示，其进化前的CP值用$x_{cp}$表示，种类用$x_s$表示，hp(血量)用$x_{hp}$表示，还有其他参数等；进化后的真实CP值用$\hat{y}$表示，预测CP值用$y$表示。而单个的宝可梦加上上标i即可。

## 选择模型

机器学习的`模型`是用参数表示的一组函数$f$，例如$y=b+wx_{cp}$，这个函数有两个参数$w(weight),b(bias)$，自变量仅是$x_{cp}$，那么$y=b+wx_{cp}$可以表示$w,b$取任意值的一组函数，它就构成一个模型。机器的目的就是在这些函数中找到最好的一个来输出预测。

## 判断函数好坏

机器判断函数好坏是通过训练+调整的方式。当确定好了模型用哪些参数和自变量表示之后：

1. 选一定量的真实数据作为**训练集**(宝可梦$x^1,x^2,\dots,x^n$和其真实的的进化后CP值$\hat{y}^1,\hat{y}^2,\dots,\hat{y}^n$)
2. 对模型中的每一个函数$f_i$(每一组$w,b$值)，将训练集中的自变量($x_{cp}$等)代入，计算出该函数得到的所有预测CP值$y^1,y^2,\dots,y^n$。
3. 定义一个`损失函数(Loss Fuction)`，用来评判函数$f_i$的预测结果好坏。例如我们可以用方差值*n来评判，即$L(f) = \sum^{10}_{n=1}(\hat{y}^n-f(x_{cp}^n))^2$（训练集有10个宝可梦）。(线代可以直接解?)
4. 那么让损失函数值最小的函数$f^*$就是我们要找的最好的函数。即$f^*=arg\ min_f L(f)$或者$w^*,b^*=arg\ min_{w,b}L(w,b)$

## 找最好的函数

将损失函数作图，也许你一眼就能看出最低点，或者利用一些数学解法，也能很快找到，但是有什么通用的方法让机器能够找到最小的那个呢？我们可以采用`梯度下降(Gradient Descent)`的方法：(配合图示)

1. 随机找一个$w$值：$w^0$，计算损失函数在该处的切线斜率: $\frac{dL}{dw}|_{w=w^0}$
2. 当斜率为负，往右走才能找到最低点，因此新的$w^1 = w^0 - \eta \frac{dL}{dw}|_{w=w^0}$，其中$\eta$称之为`学习率(Learning Rate)`；斜率为正亦然。
3. 往复进行下去，直到斜率为0，则已经找到了该方法认为的最小值点。但这个值有可能仅是局部最小(Local Minimum)而非全局最小(Global Minimum)，当Loss函数是凸函数的时候，这个值就是全局最小。

![](..\imgs\2.png)

上面是仅有一个参数$w$的方法，那么有多个参数呢？——在随机点上，让每个参数对$L$求偏导，再根据学习率更新即可。以2个参数为例，即：
$$
w^1 = w^0 - \eta\frac{\partial L}{\partial w}|_{w=w^0,b=b^0}\\
b^1 = b^0 - \eta\frac{\partial L}{\partial b}|_{w=w^0,b=b^0}
$$
对应的等高线如图所示，每次更新，就是在椭圆上做该点的法线。

![](..\imgs\3.png)

## 结果

### 单自变量

当我们的模型是$y=b+wx_{cp}$，找到的最好的函数是$y=-188.4+2.7x_{cp}$. 此时**训练集**的预测值和真实值之间差的平均值(`训练误差`)是31.9，而**测试集**(`测试误差`)是35.0，如图所示：

![](..\imgs\4.png)

这显然不够好，那当我们的模型是$y=b+w_1x_{cp}+w_2(x_{cp})^2$呢？此时最好的函数是$y=-10.3+x_{cp}+2.7\times10^{-3}(x_{cp})^2$，那么这时候的**训练误差**是15.4，**测试误差**是18.4.

同理，当我们增加三次项的分析，得到的**训练误差**是15.3，**测试误差**是18.1. 因为我们每增加一次，后面的函数组范围总是包含前面的函数组，那么就能找到在前面的基础上更好的函数。



可是当我们增加到四次项、五次项的时候，**训练误差**在逐渐减小，**测试误差**却逐渐增大并且十分夸张：

![](..\imgs\5.png)



尽管我们一直在找训练集上更好的函数，但是这个函数在测试集上的表现却并不一定更好，这种现象叫做`过拟合(Overfitting)`。因此我们不一定要追求复杂的模型，而要找到最合适的模型。

### 多自变量

很显然，宝可梦的进化后CP值还会和宝可梦的种类有关，不同种类的曲线可能不同；当是Pidgey时，曲线是$y=b1+w_1x_{cp}$,...,以此类推。得到如下的公式，此时的**训练误差**是3.8，**测试误差**是14.3.

<img src="..\imgs\6.png" style="zoom:150%;" />

同样，我们也可以在此基础上引入$x_{cp}^2$，再来查看误差结果。



我们还有什么办法能够减少误差吗？

可以在原来的Loss定义上，加上一个`正则项(Regularization term)`：函数是$y=b+\sum w_ix_i$，那么损失函数是$L=\sum_n(\hat{y}^n-(b+\sum w_ix_i))^2+\lambda \sum(w_i)^2$，当整个Loss Function越小，即方差项和正则项越小，所选择的函数越好。正则项的作用是，保证参数$w$足够小，这样函数对输入的变化更不敏感，输出的变化引起的函数变化就不会太突兀，整个函数越`平滑`。

其中$\lambda$是我们可以手动调的参数，如图，当$\lambda$逐渐增加，也就意味着正则项对loss的影响力越大，选择的最优函数会考虑$w$小的，函数会越平滑。此时**训练误差**会逐渐上升，因为当正则项影响越大，对$w$的选择就越偏离没有正则项时的$w$了；而**测试误差**却不一定会上升。图中可以看到测试误差降到$\lambda=100$后增加，由此可见，我们也不希望出现太平滑的曲线(一条直线).

![](..\imgs\7.png)

## 结果分析

接下来我们分析上面的误差来自哪里，我们假设计算进化后CP值的**实际**函数是$\hat{f}$，在训练集中我们找到的最优函数是$f^*$，那么$f^*$是$\hat{f}$的一种估计。

> 在概率论中我们知道，如果对样本空间$X$进行取样$\{x^1,x^2,...,x^N\}$，得到的其均值$m$并不一定等于整个样本空间的均值$\mu$，因此$m$也是$\mu$的一种估计。但是$m$的期望等于$\mu$: $E[m]=E[\frac{1}{N}\sum_nx^n]=\frac{1}{N}\sum_nE[x^n]=\mu$. 因此我们可以说对$\mu$的估计$m$是`无偏(unbiased)`的。

> 同样，根据$m$计算出来的方差$s^2$也不等于最终的方差$\sigma^2$,其期望也不等于$\sigma^2$: $E[s^2]=\frac{N-1}{N}\sigma^2 \not= \sigma^2$. 因此我们可以说对$\sigma^2$的估计$s^2$是`有偏(biased)`的。

我们用靶子描述模型的选择，$\hat{f}$就是靶心，模型在不同训练集上得到的最优函数$f^*$是靶上的点。记$f^*$的均值是$\bar{f}$，那么$\bar{f}$到$\hat{f}$的距离称之为`Bias`，不同$f^*$到$\bar{f}$之间的距离称之为`Variance`. 其中不同的$f^*$来源于不同的训练集，可以直观地这样理解：在训练集上训练的模型肯定会尽可能顾及到训练集上的所有点，因此不同的训练集$f^*$必然不同；在前面的过程中我们也可以知道，Loss函数的取值是依赖于训练集的真实输出的，因此根据Loss来选择的最优函数$f^*$也必然不同。

![](..\imgs\8.png)

仍以之前的宝可梦为例，假设实际的函数$\hat{f}$曲线是图中黑色曲线，红色曲线为对应模型在不同训练集上选出的$f^*$，蓝色曲线是$f^*$的平均值$\bar{f}$:

![](..\imgs\9.png)

根据图示我们可以知道，**简单的模型Bias大Variance小，复杂的模型Bias小Variance大。**因为简单的模型受训练集数据的影响较小(极限例子model:$f(x)=c$根本不会受数据影响)，其Variance就小；而复杂模型更有可能包含实际函数$\hat{f}$，因此其Bias小(在target周围),但由于数据集不够完善也许不能模拟到$\hat{f}$。



现在我们知道**误差来源于Bias和Variance**了，我们希望同时找到较小的Bias和较小的Variance：？

- 当我们遇到较大的**Bias**时，此时我们的$f^*$甚至不能完全覆盖训练集的例子——`Underfitting`
  - 重新设计模型：增加新的自变量(物种，hp值等)，设计更复杂的模型。
- 当我们遇到较大的**Variance**时，此时测试集数据误差很大——`Overfitting`
  - 增大训练集
  - 正则化

除此之外，我们也可以从训练集中分一部分出来作为**验证集**，在真正测试之前进行验证：

![](..\imgs\10.png)

如图，将训练集中的1/3作为验证集，其余的训练model，得到不同model在验证集上的误差。选择不同份的数据作为验证集，找到平均err最小的model，重新用整个训练集进行训练，再到测试集测试。



## 总结

回归分析其实是找输入输出的对应关系，好预测输出值。

我们用机器学习进行回归分析时，首先需要找到模型（函数组），通过训练模型的方法得到这个模型中最优的参数。

**如何选择最优？**

——定义损失函数，通过梯度下降的方式找到损失函数最小值点，这个点就是模型中最优的参数。

**误差来源？**

——bias和variance

当bias过大，模型不够复杂，需要更换模型；当variance过大，训练集不够大，添加正则化。

































































